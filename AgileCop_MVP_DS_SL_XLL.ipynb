{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA3bGZ1dK9H3"
      },
      "source": [
        "# 0 - Notebook Preparation\n",
        "\n",
        "* Libraries\n",
        "* Datasets\n",
        "* Global Functions\n",
        "\n",
        "Author: Pedro Ciancaglini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3s1irJaenXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d01a544b-e1f4-4c10-e122-7f8f9b65d45d"
      },
      "source": [
        "# Mounting Google Colab Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw8Mc8X_-yJG"
      },
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19xHJ9MSIOoa",
        "outputId": "ddb3ce37-34f4-47ac-9898-32445943ff92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# Global Functions for this Notebook\n",
        "\n",
        "# Importing the dataset\n",
        "def importsets():\n",
        "    train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/1.TrainXLL.csv')\n",
        "    test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/96.TestXLL.csv')\n",
        "    results = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/96.TestXLL.csv')\n",
        "    return train, test, results\n",
        "\n",
        "'''\n",
        "Use this to split between test and set if needed\n",
        "X = train_df.iloc[:, :-1].values\n",
        "y = train_df.iloc[:, -1].values\n",
        "'''\n",
        "# Calling function to set global variables for information goals\n",
        "train_df, test_df, results_df = importsets()\n",
        "\n",
        "\n",
        "# Function to show columns of imported Datasets\n",
        "def cols():\n",
        "    print('Train Columns> ' , train_df.columns)\n",
        "    print('Test Columns> ' , test_df.columns)\n",
        "    print('Result Columns> ' , results_df.columns)\n",
        "\n",
        "# Function to measure performance of models using precision, recall and F1\n",
        "def performance(test, pred):\n",
        "    print(\"Precision Score: \\t {0:.4f}\".format(precision_score(test,\n",
        "                                                            pred,\n",
        "                                                            average='weighted')))\n",
        "    print(\"Recall Score: \\t\\t {0:.4f}\".format(recall_score(test,\n",
        "                                                        pred,\n",
        "                                                        average='weighted')))\n",
        "    print(\"F1 Score: \\t\\t {0:.4f}\".format(f1_score(test,\n",
        "                                                pred,\n",
        "                                                average='weighted')))\n",
        "    cm = confusion_matrix(test, pred)\n",
        "    print(cm)\n",
        "    print('Accuracy: ', accuracy_score(test, pred))\n",
        "\n",
        "# Function to split train dataset in y column with target and the rest on X\n",
        "def create_x_y(train_df):\n",
        "    X = train_df.iloc[:, :-1].values\n",
        "    y = train_df.iloc[:, -1].values\n",
        "    return X, y\n",
        "\n",
        "def myfunctions():\n",
        "    print('importsets() useful for importing datasets to new variables train, test, results')\n",
        "    print('cols() is a function to know the columns of the original datasets')\n",
        "    print('performance(y_test, y_test_pred) is a function to know the performance of the model')\n",
        "    print('create_x_y(train_df) is a function will return y target from train and X for the rest of the columns')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8c99d3e94f8f>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m '''\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Calling function to set global variables for information goals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-8c99d3e94f8f>\u001b[0m in \u001b[0;36mimportsets\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Importing the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimportsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/1.TrainXLL.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/96.TestXLL.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/96.TestXLL.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/1.TrainXLL.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSMYTnBQFbeT"
      },
      "source": [
        "# 1 - MS Identification\n",
        "\n",
        "Splinting MS = 1 and MS = 0.\n",
        "\n",
        "MS = 1 are US between 5 SP and 3 SP each. It remains to identify whether it's small (3SP) or not, to make a final split.\n",
        "\n",
        "XLL = 0 are US between 8 SP and 13 SP. It remains to identify whether it's large (8 SP) or not, to make a final split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-bFxt1Vikqq"
      },
      "source": [
        "## 1.1 - MS Identification Starts\n",
        "\n",
        "Preparing Dataset\n",
        "\n",
        "All variables and models with identification MS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ispwLF_fiFbM"
      },
      "source": [
        "# Importing the dataset\n",
        "train_MS, results_test_MS, results_MS = importsets()\n",
        "\n",
        "# Spliting Datasets in X and Y for fitting\n",
        "X_MS = train_MS.iloc[:, :-1].values\n",
        "y_MS = train_MS.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLrYAcujsEfj"
      },
      "source": [
        "# cols() # Checking columns of all datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wW-9NqiiRsC"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_MS, y_MS, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8Atyy0iiXDc"
      },
      "source": [
        "# Fitting Gradient Boosting to the Training set\n",
        "classifier_MS = GradientBoostingClassifier(max_depth=10, random_state=10)\n",
        "classifier_MS.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnvVD9AT2z_r"
      },
      "source": [
        "y_pred_MS = classifier_MS.predict(X_MS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcSIBlko3OQo"
      },
      "source": [
        "# classifier.predict_proba(X_XLL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUxgYe3w3RXo"
      },
      "source": [
        "# Visualizing Result\n",
        "# pred_test = pd.DataFrame(data=y_pred_XLL)\n",
        "# train_test = pd.DataFrame(data=y_train)\n",
        "\n",
        "# h_stack_test = pd.concat([train_test, pred_test], axis=1)\n",
        "\n",
        "# h_stack_test.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmvzaK41N6VW"
      },
      "source": [
        "## 1.2 - Measuring Performance of Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ0jQBcnPSq6"
      },
      "source": [
        "performance(y_train, y_pred_MS[:len(y_train)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPde9NCu4RNK"
      },
      "source": [
        "del results_test_MS['ID']\n",
        "# del results_test_lg['SP']\n",
        "# del results_test_lg['XL']\n",
        "# del results_test_lg['L']\n",
        "# del results_test_lg['M']\n",
        "# del results_test_lg['S']\n",
        "# del results_test_lg['XS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOwjU_BQ4ZK6"
      },
      "source": [
        "# results_test_XLL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX-ljyxsNvCr"
      },
      "source": [
        "## 1.3 - Predicting on Prediction Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy5pK-Bc4bki"
      },
      "source": [
        "real_pred_MS = classifier.predict(results_test_MS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-ZpgQkJ4qKo"
      },
      "source": [
        "final_result_MS = pd.concat([results_MS, pd.DataFrame(real_pred_MS)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpa0QBDC44jH"
      },
      "source": [
        "#final_result_XLL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lan2ZIzFPrTV"
      },
      "source": [
        "performance(y_MS, y_pred_MS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYHtk8hD5peb"
      },
      "source": [
        "final_result_MS = final_result_MS.rename(columns={0: 'MS'})\n",
        "len(final_result_MS[final_result_MS['MS']== 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83AO7Qw7qtgZ"
      },
      "source": [
        "def AgileCop():\n",
        "    WIID = int(input('Please type the Work Item ID to estimate: '))\n",
        "    #bool_pred = int(final_result.loc[final_result['WIID'] == WIID].SP_Pred.to_string(index=False))\n",
        "    #bool_est = int(final_result.loc[final_result['WIID'] == WIID].SP.to_string(index=False))\n",
        "    #res_pred = final_result.loc[final_result['WIID'] == WIID].SP_Pred.to_string(index=False)\n",
        "    #res_est = final_result.loc[final_result['WIID'] == WIID].SP.to_string(index=False)\n",
        "\n",
        "    #if bool_pred < bool_est:\n",
        "       #print('Original Estimation for this US> ', res_est)\n",
        "       #print('Suggested Estimation for this US> ', final_result.loc[final_result['WIID'] == WIID].SP_Pred)\n",
        "    #elif bool_pred == 0:\n",
        "       #print('Suggested consideration for this US> ', res_est)\n",
        "    #else:\n",
        "       #print('Suggested consideration for this US> ', res_pred)\n",
        "\n",
        "    return final_result_MS.loc[final_result_MS['WIID'] == WIID]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPQyGb-JBZcc"
      },
      "source": [
        "## 1.4 - Results\n",
        "\n",
        "Predicting MS = 1 or 0, results in spliting those User Stories with Medium or Small size from those with Large or Extra Large size.\n",
        "\n",
        "Those records MS = 1 are Medium or Small. The coming steps is to train a model with small records labeled and identify those small records in the productive dataset. Those S = 1 are 3 SP long, and those S = 0 are 5 SP.\n",
        "\n",
        "Those records with MS = 0 are Large or Extra Large. The coming steps is to train a model with Large records labeled and identify those large records in the productive dataset. Those L = 1 are 8 SP long, and those L = 0 are 13 SP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1elKefmPUGc"
      },
      "source": [
        "# 2 - S Identification\n",
        "\n",
        "MS = 1 are Small (3 SP) or Medium (5 SP).\n",
        "In this exercise, all labeled MS = 1, with label S = 1 or 0 will be part of the training.\n",
        "\n",
        "The final result will be the testing set resulting from the previous algorithm with MS = 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUH_rjotPUGh"
      },
      "source": [
        "## 2.1 - S Identification Starts\n",
        "\n",
        "Preparing Dataset. Results are stored in results_S with the outcome from the previous one, MS = 0 and 1.\n",
        "\n",
        "Train and Test sets are datasets with labeled S = 1 or 0, in a group of MS records only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9SBU9s8PUGi"
      },
      "source": [
        "# Importing the dataset\n",
        "#train_XLL, results_test_XLL, results_XLL = importsets()\n",
        "\n",
        "train_S = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/2.TrainL.csv')\n",
        "test_S = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/97.TestL.csv')\n",
        "results_S = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/97.TestL.csv')\n",
        "\n",
        "# Spliting Datasets in X and Y for fitting\n",
        "X_L = train_L.iloc[:, :-1].values\n",
        "y_L = train_L.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Monohs-0PUGi"
      },
      "source": [
        "# cols() # Checking columns of all datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g64S8UDPUGi"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_L, y_L, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEaCB4mSPUGi"
      },
      "source": [
        "# Fitting Gradient Boosting to the Training set\n",
        "classifier_L = GradientBoostingClassifier(max_depth=10, random_state=10)\n",
        "classifier_L.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY4AtLvMPUGi"
      },
      "source": [
        "y_pred_L = classifier_L.predict(X_L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1-nuAzLPUGi"
      },
      "source": [
        "# classifier.predict_proba(X_XLL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHsATR1TPUGi"
      },
      "source": [
        "# Visualizing Result\n",
        "# pred_test = pd.DataFrame(data=y_pred_XLL)\n",
        "# train_test = pd.DataFrame(data=y_train)\n",
        "\n",
        "# h_stack_test = pd.concat([train_test, pred_test], axis=1)\n",
        "\n",
        "# h_stack_test.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLM3gzB6PUGj"
      },
      "source": [
        "## 2.2 - Measuring Performance of Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbib_ZxpPUGj"
      },
      "source": [
        "performance(y_train, y_pred_L[:len(y_train)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mfNL7gUPUGj"
      },
      "source": [
        "#del results_L['ID']\n",
        "# del results_test_lg['SP']\n",
        "# del results_test_lg['XL']\n",
        "# del results_test_lg['L']\n",
        "# del results_test_lg['M']\n",
        "# del results_test_lg['S']\n",
        "# del results_test_lg['XS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ystfQ2oAPUGj"
      },
      "source": [
        "# results_test_XLL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS-cxc1GPUGj"
      },
      "source": [
        "## 2.3 - Predicting on Prediction Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tcm9RtZXuAO"
      },
      "source": [
        "del final_result_XLL['ID']\n",
        "XLL_filtered_L = final_result_XLL[final_result_XLL['XLL']== 1].iloc[:, :-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVGdf2HAPUGj"
      },
      "source": [
        "real_pred_L = classifier_L.predict(XLL_filtered_L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anrVf8nqPUGj"
      },
      "source": [
        "final_result_L = pd.concat([results_L, pd.DataFrame(real_pred_L)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "carq80xuPUGj"
      },
      "source": [
        "final_result_L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUlhaUshPUGj"
      },
      "source": [
        "performance(y_L, y_pred_L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxzhPdXHPUGj"
      },
      "source": [
        "final_result_L = final_result_L.rename(columns={0: 'L'})\n",
        "len(final_result_L[final_result_L['L']== 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVi0Mtou72ke"
      },
      "source": [
        "final_result_L[final_result_L['L']== 1] # All Large (8 SP) US"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmpa_muS8mgX"
      },
      "source": [
        "final_result_L[final_result_L['L']== 0] # All X_Large (13 SP) US"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "162fgRfBBRqG"
      },
      "source": [
        "# 2 - L Identification\n",
        "\n",
        "XLL = 1 are US between 13 SP and 8 SP each. It remains to identify whether it's large (8SP) or not, to make a final split.\n",
        "\n",
        "Training with a new dataset, testing with previous result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjMNXQwhBRqL"
      },
      "source": [
        "## 2.1 - L Identification Starts\n",
        "\n",
        "Preparing Dataset\n",
        "\n",
        "All variables and models with identification XLL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3tOAeIMBRqL"
      },
      "source": [
        "# Importing the dataset\n",
        "#train_XLL, results_test_XLL, results_XLL = importsets()\n",
        "\n",
        "train_L = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/2.TrainL.csv')\n",
        "test_L = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/97.TestL.csv')\n",
        "results_L = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/97.TestL.csv')\n",
        "\n",
        "# Spliting Datasets in X and Y for fitting\n",
        "X_L = train_L.iloc[:, :-1].values\n",
        "y_L = train_L.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFKbYH_2BRqL"
      },
      "source": [
        "# cols() # Checking columns of all datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSWnQxMoBRqL"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_L, y_L, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgdW2WkVBRqL"
      },
      "source": [
        "# Fitting Gradient Boosting to the Training set\n",
        "classifier_L = GradientBoostingClassifier(max_depth=10, random_state=10)\n",
        "classifier_L.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNAdmPBlBRqL"
      },
      "source": [
        "y_pred_L = classifier_L.predict(X_L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iMnq82IBRqL"
      },
      "source": [
        "# classifier.predict_proba(X_XLL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbs7MobGBRqL"
      },
      "source": [
        "# Visualizing Result\n",
        "# pred_test = pd.DataFrame(data=y_pred_XLL)\n",
        "# train_test = pd.DataFrame(data=y_train)\n",
        "\n",
        "# h_stack_test = pd.concat([train_test, pred_test], axis=1)\n",
        "\n",
        "# h_stack_test.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fINhIf08BRqL"
      },
      "source": [
        "## 2.2 - Measuring Performance of Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVwSLT70BRqM"
      },
      "source": [
        "performance(y_train, y_pred_L[:len(y_train)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYG0EbEEBRqM"
      },
      "source": [
        "#del results_L['ID']\n",
        "# del results_test_lg['SP']\n",
        "# del results_test_lg['XL']\n",
        "# del results_test_lg['L']\n",
        "# del results_test_lg['M']\n",
        "# del results_test_lg['S']\n",
        "# del results_test_lg['XS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEu7os8aBRqM"
      },
      "source": [
        "# results_test_XLL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe7wO5aPBRqM"
      },
      "source": [
        "## 2.3 - Predicting on Prediction Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XccIjHzCBRqM"
      },
      "source": [
        "del final_result_XLL['ID']\n",
        "XLL_filtered_L = final_result_XLL[final_result_XLL['XLL']== 1].iloc[:, :-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz_bxT83BRqM"
      },
      "source": [
        "real_pred_L = classifier_L.predict(XLL_filtered_L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqhqjE0vBRqM"
      },
      "source": [
        "final_result_L = pd.concat([results_L, pd.DataFrame(real_pred_L)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaJJp6UhBRqM"
      },
      "source": [
        "final_result_L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCIzIuQgBRqM"
      },
      "source": [
        "performance(y_L, y_pred_L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9o9ZwwkBRqM"
      },
      "source": [
        "final_result_L = final_result_L.rename(columns={0: 'L'})\n",
        "len(final_result_L[final_result_L['L']== 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q3CimBVBRqN"
      },
      "source": [
        "final_result_L[final_result_L['L']== 1] # All Large (8 SP) US"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Of29ZLEBRqN"
      },
      "source": [
        "final_result_L[final_result_L['L']== 0] # All X_Large (13 SP) US"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HpRKntM347I"
      },
      "source": [
        "# 3 - MS Identification\n",
        "\n",
        "XLL = 0 are US between 5 SP and 3 SP each.\n",
        "It remains to identify whether it's S (3 SP) or not, to make a final split.\n",
        "\n",
        "Training with a new dataset, testing with previous result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPqQbzJS347O"
      },
      "source": [
        "## 3.1 - S Identification Starts\n",
        "\n",
        "Preparing Dataset\n",
        "\n",
        "All variables and models with identification XLL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYTKfmZQ347O"
      },
      "source": [
        "# Importing the dataset\n",
        "#train_XLL, results_test_XLL, results_XLL = importsets()\n",
        "\n",
        "train_S = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/3.TrainS.csv')\n",
        "test_S = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/98.TestS.csv')\n",
        "results_S = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/98.COB/DS/DSXL_v2/98.TestS.csv')\n",
        "\n",
        "# Spliting Datasets in X and Y for fitting\n",
        "X_S = train_S.iloc[:, :-1].values\n",
        "y_S = train_S.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tay6uD81347O"
      },
      "source": [
        "# cols() # Checking columns of all datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UohD2Pg347O"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_S, y_S, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPbtgOeh347P"
      },
      "source": [
        "# Fitting Gradient Boosting to the Training set\n",
        "classifier_S = GradientBoostingClassifier(max_depth=10, random_state=10)\n",
        "classifier_S.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7nyjb8B347P"
      },
      "source": [
        "y_pred_S = classifier_S.predict(X_S)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwQxujGJ347P"
      },
      "source": [
        "# classifier.predict_proba(X_XLL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0-iZy5W347P"
      },
      "source": [
        "# Visualizing Result\n",
        "# pred_test = pd.DataFrame(data=y_pred_XLL)\n",
        "# train_test = pd.DataFrame(data=y_train)\n",
        "\n",
        "# h_stack_test = pd.concat([train_test, pred_test], axis=1)\n",
        "\n",
        "# h_stack_test.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxtdLZjr347P"
      },
      "source": [
        "## 3.2 - Measuring Performance of Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZxzm-iX347Q"
      },
      "source": [
        "performance(y_train, y_pred_S[:len(y_train)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezhzPAzv347Q"
      },
      "source": [
        "#del results_L['ID']\n",
        "# del results_test_lg['SP']\n",
        "# del results_test_lg['XL']\n",
        "# del results_test_lg['L']\n",
        "# del results_test_lg['M']\n",
        "# del results_test_lg['S']\n",
        "# del results_test_lg['XS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ncPKS4347Q"
      },
      "source": [
        "# results_test_XLL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCCu3vsq347Q"
      },
      "source": [
        "## 3.3 - Predicting on Prediction Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNyzp_Ke347Q"
      },
      "source": [
        "XLL_filtered_S = final_result_XLL[final_result_XLL['XLL']== 0].iloc[:, :-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVLbxqV3347Q"
      },
      "source": [
        "real_pred_S = classifier_S.predict(XLL_filtered_S)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r63J6nqt347Q"
      },
      "source": [
        "final_result_S = pd.concat([results_S, pd.DataFrame(real_pred_S)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfdQHGJu347Q"
      },
      "source": [
        "final_result_S"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBx3zr4P347Q"
      },
      "source": [
        "performance(y_S, y_pred_S)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66rvmwFh347R"
      },
      "source": [
        "final_result_S = final_result_S.rename(columns={0: 'S'})\n",
        "len(final_result_S[final_result_S['S']== 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2OqeSvB6vQr"
      },
      "source": [
        "final_result_S[final_result_S['S']== 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StTbYCbNQLG1"
      },
      "source": [
        "**RESULTS**\n",
        "\n",
        "Results are good with these two examples, but performance of the algorithm is bad.\n",
        "\n",
        "Algorithms will be refined with Data Science and AI Silver badges with more deeper experience and knowledge of application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TOdzvrmPxUo"
      },
      "source": [
        "# 99 - Consume XGBoost Prototype>\n",
        "\n",
        "Now, using the trained algorithm, I'm using some \"Work Items ID\" (WIID) to test the result of the preduction (SP_Pred) agains the reality (SP)"
      ]
    }
  ]
}